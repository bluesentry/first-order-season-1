name: Upload Workflow Logs to S3 for LLM Analysis

on:
  # Trigger after the Terraform workflow completes
  workflow_run:
    workflows: ["Terraform Deploy AWS Infrastructure"]
    types:
      - completed
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      fetch_all:
        description: 'Fetch logs from all previous runs (true/false)'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
      run_id:
        description: 'Run ID of the workflow to download logs from (leave empty for latest, ignored if fetch_all is true)'
        required: false
      workflow_name:
        description: 'Name of the workflow to download logs from (default: Terraform Deploy AWS Infrastructure)'
        required: false
        default: 'Terraform Deploy AWS Infrastructure'
      max_runs:
        description: 'Maximum number of runs to fetch when fetch_all is true (default: 10)'
        required: false
        default: '10'

permissions:
  id-token: write  # Required for OIDC authentication with AWS
  contents: read
  actions: read    # Required to download workflow logs

env:
  AWS_REGION: us-east-1
  AWS_ACCOUNT_ID: 704855531002
  ROLE_NAME: BlueSentry
  S3_BUCKET: first-order-application-logs
  S3_PREFIX: log-analysis

jobs:
  upload-logs-for-llm:
    runs-on: ubuntu-latest
    
    steps:
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/${{ env.ROLE_NAME }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Generate timestamp
        id: timestamp
        run: echo "TIMESTAMP=$(date +'%Y-%m-%d-%H-%M-%S')" >> $GITHUB_ENV
      
      - name: Create temp directory for logs
        run: mkdir -p /tmp/workflow-logs
      
      - name: Set workflow name
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ -n "${{ github.event.inputs.workflow_name }}" ]; then
            echo "WORKFLOW_NAME=${{ github.event.inputs.workflow_name }}" >> $GITHUB_ENV
          else
            echo "WORKFLOW_NAME=Terraform Deploy AWS Infrastructure" >> $GITHUB_ENV
          fi
      
      - name: Get workflow ID
        id: get-workflow-id
        run: |
          REPO="${{ github.repository }}"
          WORKFLOW_ID=$(curl -s \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "https://api.github.com/repos/${REPO}/actions/workflows" | \
            jq -r '.workflows[] | select(.name=="${{ env.WORKFLOW_NAME }}") | .id')
          
          echo "WORKFLOW_ID=${WORKFLOW_ID}" >> $GITHUB_ENV
          echo "Found workflow ID: ${WORKFLOW_ID} for workflow: ${{ env.WORKFLOW_NAME }}"
      
      - name: Fetch all workflow runs
        if: ${{ github.event.inputs.fetch_all == 'true' }}
        run: |
          echo "Fetching all workflow runs for workflow ID: ${{ env.WORKFLOW_ID }}"
          
          # Get max runs to fetch
          MAX_RUNS="${{ github.event.inputs.max_runs }}"
          if [ -z "$MAX_RUNS" ]; then
            MAX_RUNS=10
          fi
          
          # Get all workflow runs
          REPO="${{ github.repository }}"
          RUNS_JSON=$(curl -s \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "https://api.github.com/repos/${REPO}/actions/workflows/${{ env.WORKFLOW_ID }}/runs?per_page=${MAX_RUNS}")
          
          # Extract run IDs
          echo "$RUNS_JSON" | jq -r '.workflow_runs[].id' > /tmp/run_ids.txt
          
          # Create a directory for all runs
          mkdir -p /tmp/all_runs
          
          # Process each run
          cat /tmp/run_ids.txt | while read RUN_ID; do
            echo "Processing run ID: ${RUN_ID}"
            
            # Create directory for this run
            mkdir -p /tmp/all_runs/run_${RUN_ID}
            
            # Get run details
            RUN_DETAILS=$(curl -s \
              -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              "https://api.github.com/repos/${REPO}/actions/runs/${RUN_ID}")
            
            # Extract run details
            RUN_NUMBER=$(echo $RUN_DETAILS | jq -r '.run_number')
            RUN_ATTEMPT=$(echo $RUN_DETAILS | jq -r '.run_attempt')
            EVENT_NAME=$(echo $RUN_DETAILS | jq -r '.event')
            ACTOR=$(echo $RUN_DETAILS | jq -r '.actor.login')
            CONCLUSION=$(echo $RUN_DETAILS | jq -r '.conclusion')
            STATUS=$(echo $RUN_DETAILS | jq -r '.status')
            CREATED_AT=$(echo $RUN_DETAILS | jq -r '.created_at')
            UPDATED_AT=$(echo $RUN_DETAILS | jq -r '.updated_at')
            
            # Create metadata file
            echo "{" > /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"repository\": \"${{ github.repository }}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"workflow_name\": \"${{ env.WORKFLOW_NAME }}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"workflow_id\": \"${{ env.WORKFLOW_ID }}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"run_id\": \"${RUN_ID}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"run_number\": \"${RUN_NUMBER}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"run_attempt\": \"${RUN_ATTEMPT}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"event_name\": \"${EVENT_NAME}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"actor\": \"${ACTOR}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"conclusion\": \"${CONCLUSION}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"status\": \"${STATUS}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"created_at\": \"${CREATED_AT}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"updated_at\": \"${UPDATED_AT}\"," >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "  \"timestamp\": \"${{ env.TIMESTAMP }}\"" >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            echo "}" >> /tmp/all_runs/run_${RUN_ID}/workflow-info.json
            
            # Download logs
            echo "Downloading logs for run ID: ${RUN_ID}"
            API_URL="https://api.github.com/repos/${REPO}/actions/runs/${RUN_ID}/logs"
            
            # Download logs zip file
            curl -L -o /tmp/all_runs/run_${RUN_ID}/logs.zip \
              -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              ${API_URL}
            
            # Extract logs
            unzip -o /tmp/all_runs/run_${RUN_ID}/logs.zip -d /tmp/all_runs/run_${RUN_ID}/ || echo "Failed to extract logs for run ${RUN_ID}"
            
            # Process logs for this run
            mkdir -p /tmp/all_runs/run_${RUN_ID}/sanitized
            mkdir -p /tmp/all_runs/run_${RUN_ID}/processed
            
            # Sanitize log filenames
            log_index=1
            find /tmp/all_runs/run_${RUN_ID} -type f -name "*.txt" | sort | while read log_file; do
              original_filename=$(basename "$log_file")
              safe_filename="log_${log_index}_${original_filename//[^a-zA-Z0-9._-]/_}"
              
              # Copy the file with a safe name
              cp "$log_file" "/tmp/all_runs/run_${RUN_ID}/sanitized/$safe_filename"
              echo "Sanitized $original_filename to $safe_filename for run ${RUN_ID}"
              
              ((log_index++))
            done
            
            # Create a consolidated log file
            echo "# Workflow Logs for Run ${RUN_ID}" > /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "## Workflow Information" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "- **Repository:** ${{ github.repository }}" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "- **Workflow:** ${{ env.WORKFLOW_NAME }}" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "- **Run ID:** ${RUN_ID}" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "- **Run Number:** ${RUN_NUMBER}" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "- **Conclusion:** ${CONCLUSION}" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "- **Created At:** ${CREATED_AT}" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            
            # Add each log file to the consolidated file
            echo "## Log Files" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            
            # Process each sanitized log file
            for log_file in $(find /tmp/all_runs/run_${RUN_ID}/sanitized -type f | sort); do
              filename=$(basename "$log_file")
              echo "Processing $filename for run ${RUN_ID}..."
              
              # Add log file header
              echo "### $filename" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
              echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
              echo '```' >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
              
              # Add log content - use cat with error handling
              if [ -f "$log_file" ]; then
                cat "$log_file" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md 2>/dev/null || echo "Error reading file content" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
              else
                echo "File not found: $log_file" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
              fi
              
              # Close code block
              echo '```' >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
              echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/consolidated_logs.md
            done
            
            # Create a JSON version for easier parsing by LLMs
            echo "Creating JSON version of logs for run ${RUN_ID}..."
            
            # Start JSON structure
            echo "{" > /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            echo "  \"workflow_info\": $(cat /tmp/all_runs/run_${RUN_ID}/workflow-info.json 2>/dev/null || echo '{}')," >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            echo "  \"log_files\": [" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            
            # Add each sanitized log file as a JSON object
            first_file=true
            for log_file in $(find /tmp/all_runs/run_${RUN_ID}/sanitized -type f | sort); do
              filename=$(basename "$log_file")
              
              # Add comma for all but the first file
              if [ "$first_file" = true ]; then
                first_file=false
              else
                echo "," >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
              fi
              
              # Safely read and escape log content
              if [ -f "$log_file" ]; then
                # Use a safer approach to escape JSON content
                log_content=$(cat "$log_file" 2>/dev/null | 
                             tr -d '\000' |  # Remove null bytes
                             sed 's/\\/\\\\/g' | # Escape backslashes
                             sed 's/"/\\"/g' |  # Escape quotes
                             sed ':a;N;$!ba;s/\n/\\n/g') # Replace newlines
                
                # If log_content is empty due to errors, provide a placeholder
                if [ -z "$log_content" ]; then
                  log_content="Error reading log content"
                fi
              else
                log_content="File not found"
              fi
              
              # Add log file as JSON object
              echo "    {" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
              echo "      \"filename\": \"$filename\"," >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
              echo "      \"content\": \"$log_content\"" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
              echo -n "    }" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            done
            
            # Close JSON structure
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            echo "  ]" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            echo "}" >> /tmp/all_runs/run_${RUN_ID}/processed/logs.json
            
            # Create a summary file
            echo "# Workflow Log Summary for Run ${RUN_ID}" > /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "## Overview" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Repository:** ${{ github.repository }}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Workflow:** ${{ env.WORKFLOW_NAME }}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Run ID:** ${RUN_ID}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Run Number:** ${RUN_NUMBER}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Triggered By:** ${ACTOR}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Event:** ${EVENT_NAME}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Status:** ${STATUS}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Conclusion:** ${CONCLUSION}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Created At:** ${CREATED_AT}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- **Updated At:** ${UPDATED_AT}" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "## Log Files" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "$(find /tmp/all_runs/run_${RUN_ID} -type f -name \"*.txt\" | wc -l) log files were captured from this workflow run." >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "## Analysis Instructions" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "These logs are intended for analysis by a Large Language Model (LLM). The logs contain:" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "1. Workflow execution details" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "2. Terraform operations (plan, apply, or destroy)" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "3. Infrastructure changes" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "4. Error messages (if any)" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "When analyzing these logs, focus on:" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- Identifying successful vs. failed operations" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- Extracting key infrastructure changes" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- Highlighting any errors or warnings" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            echo "- Providing a summary of the Terraform execution" >> /tmp/all_runs/run_${RUN_ID}/processed/summary.md
            
            # Upload logs to S3
            SAFE_WORKFLOW_NAME=$(echo "${{ env.WORKFLOW_NAME }}" | tr ' ' '_')
            RUN_ID_FOLDER="run_${RUN_ID}"
            
            echo "Uploading logs for run ${RUN_ID} to S3..."
            aws s3 sync /tmp/all_runs/run_${RUN_ID}/ "s3://${{ env.S3_BUCKET }}/${{ env.S3_PREFIX }}/workflow-logs-for-llm/${SAFE_WORKFLOW_NAME}/${RUN_ID_FOLDER}/raw/"
            aws s3 sync /tmp/all_runs/run_${RUN_ID}/processed/ "s3://${{ env.S3_BUCKET }}/${{ env.S3_PREFIX }}/workflow-logs-for-llm/${SAFE_WORKFLOW_NAME}/${RUN_ID_FOLDER}/processed/"
            
            echo "Logs for run ${RUN_ID} uploaded successfully"
          done
          
          echo "All workflow runs processed and uploaded to S3"
          exit 0
      
      - name: Determine run ID
        if: ${{ github.event.inputs.fetch_all != 'true' }}
        id: determine-run-id
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ -n "${{ github.event.inputs.run_id }}" ]; then
            echo "RUN_ID=${{ github.event.inputs.run_id }}" >> $GITHUB_ENV
          elif [ "${{ github.event_name }}" == "workflow_run" ]; then
            echo "RUN_ID=${{ github.event.workflow_run.id }}" >> $GITHUB_ENV
          else
            # Get the latest run ID of the specified workflow
            REPO="${{ github.repository }}"
            
            LATEST_RUN_ID=$(curl -s \
              -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              "https://api.github.com/repos/${REPO}/actions/workflows/${{ env.WORKFLOW_ID }}/runs?per_page=1" | \
              jq -r '.workflow_runs[0].id')
            
            echo "RUN_ID=${LATEST_RUN_ID}" >> $GITHUB_ENV
          fi
          
          echo "Using Workflow: ${{ env.WORKFLOW_NAME }}"
          echo "Using Run ID: ${{ env.RUN_ID }}"
      
      - name: Download workflow logs
        if: ${{ github.event.inputs.fetch_all != 'true' }}
        run: |
          # Download logs using GitHub API
          echo "Downloading logs for workflow run ${{ env.RUN_ID }}..."
          
          # Get workflow run info
          REPO="${{ github.repository }}"
          API_URL="https://api.github.com/repos/${REPO}/actions/runs/${{ env.RUN_ID }}/logs"
          
          # Download logs zip file
          curl -L -o /tmp/workflow-logs/logs.zip \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            ${API_URL}
          
          # Extract logs
          unzip -o /tmp/workflow-logs/logs.zip -d /tmp/workflow-logs/
          
          # List downloaded logs
          echo "Downloaded logs:"
          ls -la /tmp/workflow-logs/
      
      - name: Get workflow run details
        if: ${{ github.event.inputs.fetch_all != 'true' }}
        run: |
          REPO="${{ github.repository }}"
          RUN_DETAILS=$(curl -s \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            "https://api.github.com/repos/${REPO}/actions/runs/${{ env.RUN_ID }}")
          
          # Extract workflow name and other details
          WORKFLOW_ID=$(echo $RUN_DETAILS | jq -r '.workflow_id')
          RUN_NUMBER=$(echo $RUN_DETAILS | jq -r '.run_number')
          RUN_ATTEMPT=$(echo $RUN_DETAILS | jq -r '.run_attempt')
          EVENT_NAME=$(echo $RUN_DETAILS | jq -r '.event')
          ACTOR=$(echo $RUN_DETAILS | jq -r '.actor.login')
          CONCLUSION=$(echo $RUN_DETAILS | jq -r '.conclusion')
          STATUS=$(echo $RUN_DETAILS | jq -r '.status')
          CREATED_AT=$(echo $RUN_DETAILS | jq -r '.created_at')
          UPDATED_AT=$(echo $RUN_DETAILS | jq -r '.updated_at')
          
          # Create metadata file with workflow information
          echo "{" > /tmp/workflow-logs/workflow-info.json
          echo "  \"repository\": \"${{ github.repository }}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"workflow_name\": \"${{ env.WORKFLOW_NAME }}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"workflow_id\": \"${WORKFLOW_ID}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"run_id\": \"${{ env.RUN_ID }}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"run_number\": \"${RUN_NUMBER}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"run_attempt\": \"${RUN_ATTEMPT}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"event_name\": \"${EVENT_NAME}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"actor\": \"${ACTOR}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"conclusion\": \"${CONCLUSION}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"status\": \"${STATUS}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"created_at\": \"${CREATED_AT}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"updated_at\": \"${UPDATED_AT}\"," >> /tmp/workflow-logs/workflow-info.json
          echo "  \"timestamp\": \"${{ env.TIMESTAMP }}\"" >> /tmp/workflow-logs/workflow-info.json
          echo "}" >> /tmp/workflow-logs/workflow-info.json
      
      - name: Prepare logs for LLM analysis
        if: ${{ github.event.inputs.fetch_all != 'true' }}
        run: |
          # Create a directory for processed logs
          mkdir -p /tmp/workflow-logs/processed
          
          # Create a consolidated log file with all logs
          echo "# Workflow Logs for LLM Analysis" > /tmp/workflow-logs/processed/consolidated_logs.md
          echo "" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "## Workflow Information" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "- **Repository:** ${{ github.repository }}" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "- **Workflow:** ${{ env.WORKFLOW_NAME }}" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "- **Run ID:** ${{ env.RUN_ID }}" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "- **Timestamp:** ${{ env.TIMESTAMP }}" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "" >> /tmp/workflow-logs/processed/consolidated_logs.md
          
          # Add each log file to the consolidated file
          echo "## Log Files" >> /tmp/workflow-logs/processed/consolidated_logs.md
          echo "" >> /tmp/workflow-logs/processed/consolidated_logs.md
          
          # Create a directory to store sanitized log files
          mkdir -p /tmp/workflow-logs/sanitized
          
          # First, sanitize log filenames by copying them to a new directory with safe names
          log_index=1
          find /tmp/workflow-logs -type f -name "*.txt" | sort | while read log_file; do
            original_filename=$(basename "$log_file")
            safe_filename="log_${log_index}_${original_filename//[^a-zA-Z0-9._-]/_}"
            
            # Copy the file with a safe name
            cp "$log_file" "/tmp/workflow-logs/sanitized/$safe_filename"
            echo "Sanitized $original_filename to $safe_filename"
            
            ((log_index++))
          done
          
          # Process each sanitized log file
          for log_file in $(find /tmp/workflow-logs/sanitized -type f | sort); do
            filename=$(basename "$log_file")
            echo "Processing $filename..."
            
            # Add log file header
            echo "### $filename" >> /tmp/workflow-logs/processed/consolidated_logs.md
            echo "" >> /tmp/workflow-logs/processed/consolidated_logs.md
            echo '```' >> /tmp/workflow-logs/processed/consolidated_logs.md
            
            # Add log content - use cat with error handling
            if [ -f "$log_file" ]; then
              cat "$log_file" >> /tmp/workflow-logs/processed/consolidated_logs.md 2>/dev/null || echo "Error reading file content" >> /tmp/workflow-logs/processed/consolidated_logs.md
            else
              echo "File not found: $log_file" >> /tmp/workflow-logs/processed/consolidated_logs.md
            fi
            
            # Close code block
            echo '```' >> /tmp/workflow-logs/processed/consolidated_logs.md
            echo "" >> /tmp/workflow-logs/processed/consolidated_logs.md
          done
          
          # Create a JSON version for easier parsing by LLMs
          echo "Creating JSON version of logs..."
          
          # Start JSON structure
          echo "{" > /tmp/workflow-logs/processed/logs.json
          echo "  \"workflow_info\": $(cat /tmp/workflow-logs/workflow-info.json 2>/dev/null || echo '{}')," >> /tmp/workflow-logs/processed/logs.json
          echo "  \"log_files\": [" >> /tmp/workflow-logs/processed/logs.json
          
          # Add each sanitized log file as a JSON object
          first_file=true
          for log_file in $(find /tmp/workflow-logs/sanitized -type f | sort); do
            filename=$(basename "$log_file")
            
            # Add comma for all but the first file
            if [ "$first_file" = true ]; then
              first_file=false
            else
              echo "," >> /tmp/workflow-
